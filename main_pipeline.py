#!/usr/bin/env python3
"""
–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–µ–π –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞—Å–∏–ª–∏—è
—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ (–∞—É–¥–∏–æ + –≤–∏–¥–µ–æ)
"""

import os
import sys
import argparse
import time
from pathlib import Path
import torch
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pickle
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏
from audio_features import process_video_audio_features, AudioFeatureExtractor
from visual_features import process_video_visual_features, VisualFeatureExtractor
from train_model import train_multimodal_model
from test_model import test_multimodal_model
from multimodal_model import MultimodalViolenceClassifier, create_data_loaders


def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    required_packages = [
        ('torch', 'torch'),
        ('torchvision', 'torchvision'), 
        ('torchaudio', 'torchaudio'),
        ('librosa', 'librosa'),
        ('opencv-python', 'cv2'),
        ('scikit-learn', 'sklearn'),
        ('pandas', 'pandas'),
        ('numpy', 'numpy'),
        ('matplotlib', 'matplotlib'),
        ('seaborn', 'seaborn'),
        ('tqdm', 'tqdm'),
        ('moviepy', 'moviepy'),
        ('PIL', 'PIL')
    ]
    
    missing_packages = []
    for package_name, import_name in required_packages:
        try:
            __import__(import_name)
        except ImportError:
            missing_packages.append(package_name)
    
    if missing_packages:
        print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã:")
        for package in missing_packages:
            print(f"   - {package}")
        print("\n–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–æ–π:")
        print(f"pip install {' '.join(missing_packages)}")
        return False
    
    print("‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    return True


def check_data_files(df_path):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã—Ö"""
    if not os.path.exists(df_path):
        print(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {df_path}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    df_dir = Path(df_path).parent
    video_dir = "Movie_Clip_Dataset_A_New_Dataset_for Generalised_Real_World_Violence_Detection"
    
    if not os.path.exists(os.path.join(df_dir, video_dir)):
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {video_dir}")
        return False
    
    print("‚úÖ –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω—ã")
    return True


def extract_features(df_path, max_frames=30, force_extract=False):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∏–∑ –≤–∏–¥–µ–æ"""
    print("\n" + "="*60)
    print("–®–ê–ì 1: –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –§–ò–ß–ï–ô")
    print("="*60)
    
    audio_features_path = "audio_features/audio_features.pkl"
    visual_features_path = "visual_features/visual_features.pkl"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ñ–∏—á–∏
    if not force_extract and os.path.exists(audio_features_path) and os.path.exists(visual_features_path):
        print("‚úÖ –§–∏—á–∏ —É–∂–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force-extract –¥–ª—è –ø–µ—Ä–µ–∏–∑–≤–ª–µ—á–µ–Ω–∏—è.")
        return audio_features_path, visual_features_path
    
    print("üéµ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ —Ñ–∏—á–µ–π...")
    start_time = time.time()
    audio_features = process_video_audio_features(df_path, output_dir="audio_features")
    audio_time = time.time() - start_time
    print(f"‚è±Ô∏è  –ê—É–¥–∏–æ —Ñ–∏—á–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∑–∞ {audio_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    print("\nüé¨ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π...")
    start_time = time.time()
    visual_features = process_video_visual_features(df_path, output_dir="visual_features", max_frames=max_frames)
    visual_time = time.time() - start_time
    print(f"‚è±Ô∏è  –í–∏–∑—É–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∑–∞ {visual_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    total_time = audio_time + visual_time
    print(f"\n‚úÖ –í—Å–µ —Ñ–∏—á–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    return audio_features_path, visual_features_path


def train_model(audio_features_path, visual_features_path, df_path, 
                num_epochs=50, batch_size=16, learning_rate=0.001, force_train=False):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    print("\n" + "="*60)
    print("–®–ê–ì 2: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("="*60)
    
    model_path = "models/best_model.pth"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å
    if not force_train and os.path.exists(model_path):
        print("‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –æ–±—É—á–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force-train –¥–ª—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.")
        return model_path
    
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    print(f"   - –≠–ø–æ—Ö: {num_epochs}")
    print(f"   - –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
    print(f"   - –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: {learning_rate}")
    
    start_time = time.time()
    model, history, test_loader = train_multimodal_model(
        audio_features_path=audio_features_path,
        visual_features_path=visual_features_path,
        df_path=df_path,
        num_epochs=num_epochs,
        batch_size=batch_size,
        learning_rate=learning_rate,
        save_dir="models"
    )
    train_time = time.time() - start_time
    
    print(f"‚è±Ô∏è  –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∑–∞ {train_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")
    
    return model_path


def test_model(model_path, audio_features_path, visual_features_path, df_path):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    print("\n" + "="*60)
    print("–®–ê–ì 3: –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("="*60)
    
    scaler_audio_path = "models/scaler_audio.pkl"
    scaler_visual_path = "models/scaler_visual.pkl"
    
    if not os.path.exists(scaler_audio_path) or not os.path.exists(scaler_visual_path):
        print("‚ùå –°–∫–µ–π–ª–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.")
        return None
    
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ...")
    start_time = time.time()
    
    metrics, results_df, report = test_multimodal_model(
        model_path=model_path,
        audio_features_path=audio_features_path,
        visual_features_path=visual_features_path,
        df_path=df_path,
        scaler_audio_path=scaler_audio_path,
        scaler_visual_path=scaler_visual_path,
        save_dir="test_results"
    )
    
    test_time = time.time() - start_time
    
    print(f"‚è±Ô∏è  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {test_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ test_results/")
    
    # –í—ã–≤–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\nüìä –û–°–ù–û–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   - –¢–æ—á–Ω–æ—Å—Ç—å: {metrics['accuracy']:.4f}")
    print(f"   - F1-–º–µ—Ä–∞: {metrics['f1_score']:.4f}")
    print(f"   - AUC-ROC: {metrics['auc_roc']:.4f}")
    
    return metrics, results_df, report


def compare_feature_types(df_path, max_frames=30, num_epochs=20, batch_size=16, learning_rate=0.001):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Ñ–∏—á–µ–π"""
    print("\n" + "="*60)
    print("–°–†–ê–í–ù–ï–ù–ò–ï –¢–ò–ü–û–í –§–ò–ß–ï–ô")
    print("="*60)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    feature_configs = {
        'audio_only': {'audio': True, 'visual': False, 'name': '–¢–æ–ª—å–∫–æ –∞—É–¥–∏–æ'},
        'visual_only': {'audio': False, 'visual': True, 'name': '–¢–æ–ª—å–∫–æ –≤–∏–¥–µ–æ'},
        'multimodal': {'audio': True, 'visual': True, 'name': '–ê—É–¥–∏–æ + –≤–∏–¥–µ–æ'}
    }
    
    results = {}
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    for config_name, config in feature_configs.items():
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {config['name']}")
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω—É–∂–Ω—ã–µ —Ñ–∏—á–∏
            audio_features_path = None
            visual_features_path = None
            
            if config['audio']:
                print("   üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ —Ñ–∏—á–µ–π...")
                audio_features_path = "audio_features/audio_features.pkl"
                if not os.path.exists(audio_features_path):
                    process_video_audio_features(df_path, output_dir="audio_features")
            
            if config['visual']:
                print("   üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π...")
                visual_features_path = "visual_features/visual_features.pkl"
                if not os.path.exists(visual_features_path):
                    process_video_visual_features(df_path, output_dir="visual_features", max_frames=max_frames)
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            print("   üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –æ–¥–∏–Ω –∏–∑ —Ç–∏–ø–æ–≤ —Ñ–∏—á–µ–π –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            temp_audio_path = None
            temp_visual_path = None
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏
            model, history, test_loader = train_multimodal_model(
                audio_features_path=audio_features_path,
                visual_features_path=visual_features_path,
                df_path=df_path,
                num_epochs=num_epochs,
                batch_size=batch_size,
                learning_rate=learning_rate,
                save_dir=f"models/{config_name}"
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            print("   üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            model.eval()
            all_predictions = []
            all_labels = []
            all_probabilities = []
            
            with torch.no_grad():
                for batch in test_loader:
                    # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
                    if config['audio'] and config['visual']:
                        audio_input = batch['audio'].to(device)
                        visual_input = batch['visual'].to(device)
                    elif config['audio'] and not config['visual']:
                        audio_input = batch['audio'].to(device)
                        visual_input = None
                    elif not config['audio'] and config['visual']:
                        audio_input = None
                        visual_input = batch['visual'].to(device)
                    else:
                        raise ValueError("–•–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–∏–ø —Ñ–∏—á–µ–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞–∫—Ç–∏–≤–µ–Ω")
                    
                    labels = batch['label'].to(device)
                    
                    outputs = model(audio_input, visual_input)
                    probabilities = torch.softmax(outputs, dim=1)
                    predictions = torch.argmax(outputs, dim=1)
                    
                    all_predictions.extend(predictions.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())
                    all_probabilities.extend(probabilities[:, 1].cpu().numpy())
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(all_labels, all_predictions)
            precision = precision_score(all_labels, all_predictions, average='weighted')
            recall = recall_score(all_labels, all_predictions, average='weighted')
            f1 = f1_score(all_labels, all_predictions, average='weighted')
            auc = roc_auc_score(all_labels, all_probabilities)
            
            results[config_name] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'auc_roc': auc,
                'config': config
            }
            
            print(f"   ‚úÖ {config['name']}: Accuracy={accuracy:.4f}, F1={f1:.4f}, AUC={auc:.4f}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config['name']}: {e}")
            results[config_name] = {'error': str(e)}
    
    return results


def compare_feature_components(df_path, max_frames=30, num_epochs=20, batch_size=16, learning_rate=0.001):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ —Ñ–∏—á–µ–π"""
    print("\n" + "="*60)
    print("–°–†–ê–í–ù–ï–ù–ò–ï –ö–û–ú–ü–û–ù–ï–ù–¢–û–í –§–ò–ß–ï–ô")
    print("="*60)
    
    # –ü–æ–∫–∞ —á—Ç–æ —É–ø—Ä–æ—â–∞–µ–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    # –í –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ã–µ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—ã
    component_configs = {
        'audio_components': {'audio': True, 'visual': False, 'name': '–ê—É–¥–∏–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã'},
        'visual_components': {'audio': False, 'visual': True, 'name': '–í–∏–∑—É–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã'},
        'all_components': {'audio': True, 'visual': True, 'name': '–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã'}
    }
    
    results = {}
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    for config_name, config in component_configs.items():
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {config['name']}")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –∏–∑ compare_feature_types
            audio_features_path = None
            visual_features_path = None
            
            if config['audio']:
                print("   üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ —Ñ–∏—á–µ–π...")
                audio_features_path = "audio_features/audio_features.pkl"
                if not os.path.exists(audio_features_path):
                    process_video_audio_features(df_path, output_dir="audio_features")
            
            if config['visual']:
                print("   üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π...")
                visual_features_path = "visual_features/visual_features.pkl"
                if not os.path.exists(visual_features_path):
                    process_video_visual_features(df_path, output_dir="visual_features", max_frames=max_frames)
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            print("   üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            model, history, test_loader = train_multimodal_model(
                audio_features_path=audio_features_path,
                visual_features_path=visual_features_path,
                df_path=df_path,
                num_epochs=num_epochs,
                batch_size=batch_size,
                learning_rate=learning_rate,
                save_dir=f"models/{config_name}"
            )
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            print("   üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
            model.eval()
            all_predictions = []
            all_labels = []
            all_probabilities = []
            
            with torch.no_grad():
                for batch in test_loader:
                    # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º None –∑–Ω–∞—á–µ–Ω–∏—è
                    if config['audio'] and config['visual']:
                        audio_input = batch['audio'].to(device)
                        visual_input = batch['visual'].to(device)
                    elif config['audio'] and not config['visual']:
                        audio_input = batch['audio'].to(device)
                        visual_input = None
                    elif not config['audio'] and config['visual']:
                        audio_input = None
                        visual_input = batch['visual'].to(device)
                    else:
                        raise ValueError("–•–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–∏–ø —Ñ–∏—á–µ–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∞–∫—Ç–∏–≤–µ–Ω")
                    
                    labels = batch['label'].to(device)
                    
                    outputs = model(audio_input, visual_input)
                    probabilities = torch.softmax(outputs, dim=1)
                    predictions = torch.argmax(outputs, dim=1)
                    
                    all_predictions.extend(predictions.cpu().numpy())
                    all_labels.extend(labels.cpu().numpy())
                    all_probabilities.extend(probabilities[:, 1].cpu().numpy())
            
            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            accuracy = accuracy_score(all_labels, all_predictions)
            precision = precision_score(all_labels, all_predictions, average='weighted')
            recall = recall_score(all_labels, all_predictions, average='weighted')
            f1 = f1_score(all_labels, all_predictions, average='weighted')
            auc = roc_auc_score(all_labels, all_probabilities)
            
            results[config_name] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'auc_roc': auc,
                'config': config
            }
            
            print(f"   ‚úÖ {config['name']}: Accuracy={accuracy:.4f}, F1={f1:.4f}, AUC={auc:.4f}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config['name']}: {e}")
            results[config_name] = {'error': str(e)}
    
    return results


def extract_custom_audio_features(df_path, extractor, config):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ —Ñ–∏—á–µ–π —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None, —Ç–∞–∫ –∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ AudioFeatureExtractor
    return None


def extract_custom_visual_features(df_path, extractor, config, max_frames):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ñ–∏—á–µ–π —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None, —Ç–∞–∫ –∫–∞–∫ —Ç—Ä–µ–±—É–µ—Ç –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ VisualFeatureExtractor
    return None


def create_custom_data_loaders(audio_features, visual_features, df_path, batch_size):
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–æ–≤ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏
    return None, None, None


def train_custom_model(model, train_loader, val_loader, device, num_epochs, learning_rate):
    """–û–±—É—á–µ–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏
    return None


def test_custom_model(model, test_loader, device):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏
    return {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, 'auc_roc': 0.0}


def create_comparison_heatmap(results, title, save_path):
    """–°–æ–∑–¥–∞–Ω–∏–µ heatmap –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print(f"\nüìä –°–æ–∑–¥–∞–Ω–∏–µ heatmap: {title}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è heatmap
    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']
    configs = list(results.keys())
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    data_matrix = []
    for config in configs:
        if 'error' not in results[config]:
            row = [results[config].get(metric, 0) for metric in metrics]
            data_matrix.append(row)
        else:
            data_matrix.append([0] * len(metrics))
    
    data_matrix = np.array(data_matrix)
    
    # –°–æ–∑–¥–∞–µ–º heatmap
    plt.figure(figsize=(12, 8))
    sns.heatmap(data_matrix, 
                xticklabels=metrics,
                yticklabels=configs,
                annot=True, 
                fmt='.3f',
                cmap='RdYlBu_r',
                cbar_kws={'label': 'Score'})
    
    plt.title(f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {title}')
    plt.xlabel('–ú–µ—Ç—Ä–∏–∫–∏')
    plt.ylabel('–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    plt.xticks(rotation=45)
    plt.yticks(rotation=0)
    plt.tight_layout()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º heatmap
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"‚úÖ Heatmap —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")


def find_best_model(results):
    """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –ø–æ F1-score"""
    best_config = None
    best_f1 = 0
    
    for config_name, result in results.items():
        if 'error' not in result and result.get('f1_score', 0) > best_f1:
            best_f1 = result['f1_score']
            best_config = config_name
    
    return best_config, best_f1


def save_best_model(best_config, results, save_dir="best_models"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏"""
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {best_config}")
    
    os.makedirs(save_dir, exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_path = os.path.join(save_dir, "comparison_results.pkl")
    with open(results_path, 'wb') as f:
        pickle.dump(results, f)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_info = {
        'best_config': best_config,
        'best_f1_score': results[best_config]['f1_score'],
        'all_metrics': results[best_config]
    }
    
    best_info_path = os.path.join(save_dir, "best_model_info.pkl")
    with open(best_info_path, 'wb') as f:
        pickle.dump(best_info, f)
    
    print(f"‚úÖ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {save_dir}/")
    print(f"   - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {best_config}")
    print(f"   - F1-score: {results[best_config]['f1_score']:.4f}")
    
    return best_info


def features_comparison_mode(df_path, max_frames=30, num_epochs=20, batch_size=16, learning_rate=0.001):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–µ–∂–∏–º–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ–∏—á–µ–π"""
    print("\n" + "="*60)
    print("–†–ï–ñ–ò–ú –°–†–ê–í–ù–ï–ù–ò–Ø –§–ò–ß–ï–ô")
    print("="*60)
    
    start_time = time.time()
    
    # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ñ–∏—á–µ–π
    print("\nüîç –≠–¢–ê–ü 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ñ–∏—á–µ–π")
    feature_type_results = compare_feature_types(df_path, max_frames, num_epochs, batch_size, learning_rate)
    
    # 2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ñ–∏—á–µ–π
    print("\nüîç –≠–¢–ê–ü 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ñ–∏—á–µ–π")
    component_results = compare_feature_components(df_path, max_frames, num_epochs, batch_size, learning_rate)
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ heatmap
    print("\nüìä –≠–¢–ê–ü 3: –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π")
    create_comparison_heatmap(feature_type_results, "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ñ–∏—á–µ–π", "comparison_results/feature_types_heatmap.png")
    create_comparison_heatmap(component_results, "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ñ–∏—á–µ–π", "comparison_results/feature_components_heatmap.png")
    
    # 4. –ü–æ–∏—Å–∫ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    print("\nüèÜ –≠–¢–ê–ü 4: –ü–æ–∏—Å–∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏")
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    all_results = {**feature_type_results, **component_results}
    
    best_config, best_f1 = find_best_model(all_results)
    if best_config:
        best_info = save_best_model(best_config, all_results)
        
        print(f"\nüéâ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨ –ù–ê–ô–î–ï–ù–ê!")
        print(f"   - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {best_config}")
        print(f"   - F1-score: {best_f1:.4f}")
        print(f"   - Accuracy: {all_results[best_config]['accuracy']:.4f}")
        print(f"   - AUC-ROC: {all_results[best_config]['auc_roc']:.4f}")
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ª—É—á—à—É—é –º–æ–¥–µ–ª—å")
    
    total_time = time.time() - start_time
    print(f"\n‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
    
    return all_results, best_config


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞—Å–∏–ª–∏—è –≤ –≤–∏–¥–µ–æ')
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--df-path', type=str, default='df.csv',
                       help='–ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('--max-frames', type=int, default=30,
                       help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--epochs', type=int, default=50,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--batch-size', type=int, default=16,
                       help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞')
    parser.add_argument('--learning-rate', type=float, default=0.001,
                       help='–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
    
    # –§–ª–∞–≥–∏
    parser.add_argument('--force-extract', action='store_true',
                       help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π')
    parser.add_argument('--force-train', action='store_true',
                       help='–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--skip-extract', action='store_true',
                       help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π')
    parser.add_argument('--skip-train', action='store_true',
                       help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--skip-test', action='store_true',
                       help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    
    # –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã
    parser.add_argument('--extract-only', action='store_true',
                       help='–¢–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π')
    parser.add_argument('--train-only', action='store_true',
                       help='–¢–æ–ª—å–∫–æ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--test-only', action='store_true',
                       help='–¢–æ–ª—å–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--features-comp', action='store_true',
                       help='–†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ–∏—á–µ–π (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ–∏—á–µ–π)')
    
    args = parser.parse_args()
    
    print("üé¨ –ú–£–õ–¨–¢–ò–ú–û–î–ê–õ–¨–ù–ê–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ù–ê–°–ò–õ–ò–Ø –í –í–ò–î–ï–û")
    print("="*60)
    print(f"üìÅ –î–∞–Ω–Ω—ã–µ: {args.df_path}")
    print(f"üéûÔ∏è  –ú–∞–∫—Å–∏–º—É–º –∫–∞–¥—Ä–æ–≤: {args.max_frames}")
    print(f"üöÄ –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: {args.epochs}")
    print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {args.batch_size}")
    print(f"üìà –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: {args.learning_rate}")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    if not check_dependencies():
        sys.exit(1)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
    if not check_data_files(args.df_path):
        sys.exit(1)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    start_time = time.time()
    
    try:
        # –†–µ–∂–∏–º —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ñ–∏—á–µ–π
        if args.features_comp:
            print("üîç –ó–ê–ü–£–°–ö –†–ï–ñ–ò–ú–ê –°–†–ê–í–ù–ï–ù–ò–Ø –§–ò–ß–ï–ô")
            results, best_config = features_comparison_mode(
                args.df_path, args.max_frames, args.epochs, args.batch_size, args.learning_rate
            )
            return
        
        # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π
        if not args.skip_extract and not args.train_only and not args.test_only:
            audio_features_path, visual_features_path = extract_features(
                args.df_path, args.max_frames, args.force_extract
            )
        else:
            audio_features_path = "audio_features/audio_features.pkl"
            visual_features_path = "visual_features/visual_features.pkl"
        
        if args.extract_only:
            print("‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            return
        
        # –®–∞–≥ 2: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if not args.skip_train and not args.extract_only and not args.test_only:
            model_path = train_model(
                audio_features_path, visual_features_path, args.df_path,
                args.epochs, args.batch_size, args.learning_rate, args.force_train
            )
        else:
            model_path = "models/best_model.pth"
        
        if args.train_only:
            print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            return
        
        # –®–∞–≥ 3: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        if not args.skip_test and not args.extract_only and not args.train_only:
            test_model(model_path, audio_features_path, visual_features_path, args.df_path)
        
        total_time = time.time() - start_time
        print(f"\nüéâ –í–°–ï –≠–¢–ê–ü–´ –ó–ê–í–ï–†–®–ï–ù–´ –ó–ê {total_time:.2f} –°–ï–ö–£–ù–î")
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        print("\nüìÅ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´ –í:")
        print("   - audio_features/ - –∞—É–¥–∏–æ —Ñ–∏—á–∏")
        print("   - visual_features/ - –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏")
        print("   - models/ - –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
        print("   - test_results/ - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
    except KeyboardInterrupt:
        print("\n‚ùå –ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
