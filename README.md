# üé¨ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞—Å–∏–ª–∏—è –≤ –≤–∏–¥–µ–æ

–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–∞—Å–∏–ª—å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞—É–¥–∏–æ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

## üéØ –û–ø–∏—Å–∞–Ω–∏–µ

–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ, –∏–∑–≤–ª–µ–∫–∞—è –∞—É–¥–∏–æ –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å attention mechanism –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ –∫–ª–∞—Å—Å—ã "Violent" –∏ "Non-Violent".

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

- **–ê—É–¥–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–∏**: MFCC –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã, —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, —Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (40 –∏–∑–º–µ—Ä–µ–Ω–∏–π)
- **–í–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏**: CNN –ø—Ä–∏–∑–Ω–∞–∫–∏ (MobileNet-V3), —Ü–≤–µ—Ç–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, —Ç–µ–∫—Å—Ç—É—Ä—ã, –¥–≤–∏–∂–µ–Ω–∏–µ (1772 –∏–∑–º–µ—Ä–µ–Ω–∏—è)
- **–ú–æ–¥–µ–ª—å**: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è —Å–µ—Ç—å —Å attention fusion –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |
|---------|----------|
| **Accuracy** | **86.2%** |
| **F1-Score** | **86.2%** |
| **AUC-ROC** | **0.922** |

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r Violence_Detection/requirements.txt
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```bash
# –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω (–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ + –æ–±—É—á–µ–Ω–∏–µ + —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
cd Violence_Detection
python main_pipeline.py

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∏–¥–µ–æ
python test.py path/to/video.mp4

# –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
python gradio_app.py
```

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from Violence_Detection.test import VideoViolenceClassifier

classifier = VideoViolenceClassifier(
    model_path="Violence_Detection/models/best_model.pth",
    scaler_audio_path="Violence_Detection/models/scaler_audio.pkl",
    scaler_visual_path="Violence_Detection/models/scaler_visual.pkl"
)

result = classifier.classify_video("sample_video.mp4")
print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result['prediction']}")
print(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {result['probability']:.2%}")
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
Violence_Detection/
‚îú‚îÄ‚îÄ multimodal_model.py      # –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ train_model.py           # –û–±—É—á–µ–Ω–∏–µ
‚îú‚îÄ‚îÄ test_model.py            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îú‚îÄ‚îÄ audio_features.py        # –ê—É–¥–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–∏
‚îú‚îÄ‚îÄ visual_features.py       # –í–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
‚îú‚îÄ‚îÄ main_pipeline.py         # –ì–ª–∞–≤–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
‚îú‚îÄ‚îÄ test.py                  # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤–∏–¥–µ–æ
‚îú‚îÄ‚îÄ gradio_app.py            # –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
‚îú‚îÄ‚îÄ models/                  # –û–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îî‚îÄ‚îÄ test_results/            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
```

## üõ†Ô∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

- **Python**: 3.8+
- **PyTorch**: 1.9+
- **–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä**: Adam (lr=0.001)
- **Batch size**: 32
- **Epochs**: 50 —Å early stopping
- **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è**: StandardScaler –¥–ª—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤